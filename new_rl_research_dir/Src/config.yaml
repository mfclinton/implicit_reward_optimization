config:
  _target_: Src.run.Config
  env:
    _target_: Environments.mountain_car.MountainCarEnv
    aux_r_id: -1
  basis:
      _target_: Src.Utils.Basis.Fourier_Basis
      fourier_order: 3
      fourier_coupled: True
  agent:
    _target_: Src.Algorithms.Agent.Reinforce.Reinforce
    policy:
      _target_: Src.Utils.Policy.Categorical
      lr: 0.01582232245512644
      weight_decay: 0.016411224505373263
  reward_func:
    _target_: Src.Algorithms.Reward.RewardFunc.RewardFunc
    lr: 0.020145975806495523
  gamma_func:
    _target_: Src.Algorithms.Gamma.GammaFunc.GammaFunc
    lr: 0.024941341112339477
  gamma: 0.6503508469955804
  name: "my_experiment"
  offpolicy: True
  T1: 40
  T2: 60
  T3: 25
  buffer_size: 10000
  batch_size: 100
  weight_decay: 0.0006323627273727256
  dropped_gamma: False #nothing rn
  num_repeat_action: 3
seed: 0
num_runs: 1 #Does nothing rn
defaults:
  - override hydra/sweeper: nevergrad
  - override hydra/launcher: submitit_slurm
hydra:
  run:
    # Output directory for normal runs
    dir: ./outputs/${config.env._target_}/${config.env.aux_r_id}/${config._target_}/${config.name}/${config.offpolicy}/${num_runs}/${seed}
  sweeper:
    optim:
      optimizer: OnePlusOne
      budget: 50
      num_workers: 100
      maximize: true
    parametrization:
      config.agent.policy.lr:
        init: 0.02
        step: 2.0
        log: true
      config.agent.policy.weight_decay:
        init: 0.005
        step: 2.0
        log: true
      config.reward_func.lr:
        init: 0.02
        step: 2.0
        log: true
      config.gamma_func.lr:
        init: 0.02
        step: 2.0
        log: true
      config.gamma:
        lower: 0.0
        upper: 1.0
      config.weight_decay:
        init: 0.001
        step: 3.0
        log: true
  launcher:
    # @package hydra.launcher
    submitit_folder: $&#123;hydra.sweep.dir/.submitit/%j
    timeout_min: 600
    nodes: 4
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    array_parallelism: 256