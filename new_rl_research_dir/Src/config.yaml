config:
  _target_: Src.run.Config
  env:
    _target_: Environments.mountain_car.MountainCarEnv
    aux_r_id: -1
  basis:
      _target_: Src.Utils.Basis.Fourier_Basis
      fourier_order: 5
      fourier_coupled: True
  agent:
    _target_: Src.Algorithms.Agent.Reinforce.Reinforce
    policy:
      _target_: Src.Utils.Policy.Categorical
      lr: 0.001
      weight_decay: 0.014990644662553964
  reward_func:
    _target_: Src.Algorithms.Reward.RewardFunc.RewardFunc
    lr: 0.001
  gamma_func:
    _target_: Src.Algorithms.Gamma.GammaFunc.GammaFunc
    lr: 0.001
  gamma: 0.8011719680467164
  name: "my_experiment"
  offpolicy: True
  T1: 100
  T2: 60
  T3: 10
  buffer_size: 10000
  batch_size: 100
  weight_decay: 0.008300797153263966
  dropped_gamma: False #nothing rn
  num_repeat_action: 1
seed: 0
num_runs: 1 #Does nothing rn
defaults:
  - override hydra/sweeper: nevergrad
  - override hydra/launcher: submitit_slurm
hydra:
  run:
    # Output directory for normal runs
    dir: ./outputs/${config.env._target_}/${config.env.aux_r_id}/${config._target_}/${config.name}/${config.offpolicy}/${num_runs}/${seed}
  sweeper:
    optim:
      optimizer: OnePlusOne
      budget: 1000
      num_workers: 100
      maximize: true
    parametrization:
      config.agent.policy.lr:
        init: 0.02
        step: 2.0
        log: true
      config.agent.policy.weight_decay:
        init: 0.005
        step: 2.0
        log: true
      config.reward_func.lr:
        init: 0.02
        step: 2.0
        log: true
      config.gamma_func.lr:
        init: 0.02
        step: 2.0
        log: true
      config.gamma:
        lower: 0.0
        upper: 1.0
      config.weight_decay:
        init: 0.001
        step: 3.0
        log: true
  launcher:
    # @package hydra.launcher
    submitit_folder: $&#123;hydra.sweep.dir/.submitit/%j
    timeout_min: 600
    nodes: 4
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    array_parallelism: 256